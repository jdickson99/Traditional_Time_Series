{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Demo/PoC\n",
    "\n",
    "Notebook for training different forecast models (Holt-Winters and ARIMAX) and parameters on insurance claims data and evaluating the resulting predictions on a hold out test set.\n",
    "\n",
    "    Prepare the Data\n",
    "    0. Import Packages\n",
    "    1. Read Data\n",
    "    2. Data Preparation\n",
    "        2.1 Encoding\n",
    "    3. Pre-Processing\n",
    "        3.1 Correlation\n",
    "        3.2 Train/Test Partitioning\n",
    "    \n",
    "    Traditional Time Series Models\n",
    "    4. Train Holt-Winters Models\n",
    "    5. ARIMAX Models\n",
    "        5.1 Differencing\n",
    "        5.2 Auto-Regression\n",
    "        5.3 Moving Average\n",
    "        5.4 Train ARIMA Models\n",
    "    6. Holt-Winters & ARIMAX Comparison\n",
    "    \n",
    "    Automated Time Series Models\n",
    "    7. Auto-ARIMAX\n",
    "    8. Auto-SARIMAX\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 0.  Packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing as HWES\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import pmdarima as pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  1.  Read Data\n",
    "os.chdir(\"C:\\\\Users\\\\jodickson\\\\OneDrive - Deloitte (O365D)\\\\Documents\\\\HBF\\\\Forecasting_PoC\")\n",
    "df0 = pd.read_csv('data\\\\insurance_claims_daily.csv', header=0, index_col=0)\n",
    "df=df0\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.reset_option('max_columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  2. Data Preparation\n",
    "\n",
    "# Target Feature:  \n",
    "#   Daily Total Claim Amount \n",
    "\n",
    "\n",
    "#####  2.1 Encoding\n",
    "\n",
    "# Encode dates\n",
    "df.incident_date = pd.to_datetime(df.incident_date, format='%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  3 Pre-Processing\n",
    "\n",
    "## 3.1 Check for correlation amongst predictors\n",
    "\n",
    "# Policy state - Weak correlation with OH pct\n",
    "df[['total_claim_amount', 'policy_state_IL_pct', 'policy_state_IN_pct', 'policy_state_OH_pct']].corr()\n",
    "\n",
    "# Sex - Weak correlation\n",
    "df[['total_claim_amount', 'insured_male_pct', 'insured_female_pct']].corr()\n",
    "\n",
    "# Eductaion - Weak correlation\n",
    "df[['total_claim_amount','insured_High_School_pct', 'insured_JD_pct','insured_Associate_pct', \n",
    "          'insured_MD_pct', 'insured_Masters_pct', 'insured_PhD_pct','insured_College_pct']].corr()\n",
    "\n",
    "# Age and Customer Months - some correlation with max\n",
    "df[['total_claim_amount', 'age_mean', 'age_min', 'age_max', \n",
    "          'customer_months_mean', 'customer_months_min', 'customer_months_max']].corr()\n",
    "\n",
    "# Age Mean and Max are correlated with Customer months mean and max \n",
    "# (the older a customer is, the longer they could have been a customer)\n",
    "# Some correlations between  max age/months and claim amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  3.2 Train and test split\n",
    "# Create training set for modelling and hold-out test set for evaluation\n",
    "\n",
    "train_pct = 0.8  \n",
    "train = df.iloc[0:round(len(df)*train_pct)]\n",
    "test = df.iloc[round(len(df)*train_pct):]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Holt-Winters Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  4.   Train Holt-Winters Model\n",
    "\n",
    "hwdef = HWES(endog=train['total_claim_amount'], seasonal_periods=7, trend='add', seasonal='add', initialization_method=\"estimated\")\n",
    "hwmod = hwdef.fit()\n",
    "hwfitted = hwmod.fittedvalues\n",
    "train = pd.concat([train, pd.DataFrame({'HW_Fitted' : hwfitted})], axis=1)\n",
    "\n",
    "# Out of Sample Test\n",
    "hwforecast = hwmod.forecast(steps=len(test))\n",
    "test = pd.concat([test, pd.DataFrame({'HW_Forecast' : hwforecast})], axis=1)\n",
    "\n",
    "\n",
    "# Forecast Error\n",
    "hw_rmse = np.sqrt(np.mean((test.total_claim_amount - test.HW_Forecast)**2))\n",
    "hw_mae = np.mean(np.abs(test.total_claim_amount - test.HW_Forecast))\n",
    "print(\"RMSE: \" + str(round(hw_rmse)))\n",
    "print(\"MAE: \" + str(round(hw_mae)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Chart whole data set with test set forecast\n",
    "fig, ax = plt.subplots(figsize=(9,2.5))\n",
    "npre = 4\n",
    "ax.set(title='Total Claim Amount', xlabel='Date', ylabel='Million Dollars')\n",
    "# Plot data points\n",
    "plt.plot(df['incident_date'], df['total_claim_amount'], label='Observed',  markersize=1)\n",
    "train.plot(x='incident_date', y='HW_Fitted', ax=ax, style='orange', label='Fitted Values', linewidth=1, linestyle='--')\n",
    "# Plot predictions\n",
    "test.plot(x='incident_date', y='HW_Forecast', ax=ax, style='g', label='Out of Sample HW Forecast')\n",
    "legend = ax.legend(loc='lower right', fontsize='xx-small')\n",
    "\n",
    "\n",
    "# # Chart test set with forecast\n",
    "fig, ax = plt.subplots(figsize=(9,2.5))\n",
    "npre = 4\n",
    "ax.set(title='Total Claim Amount', xlabel='Date', ylabel='Million Dollars')\n",
    "# Plot data points\n",
    "plt.plot(test['incident_date'], test['total_claim_amount'], label='Observed', marker='o', markersize=4)\n",
    "# Plot predictions\n",
    "test.plot(x='incident_date', y='HW_Forecast', ax=ax, style='g', label='Out of Sample HW Forecast')\n",
    "legend = ax.legend(loc='lower right', fontsize='xx-small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ARIMAX Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  5.  ARIMAX\n",
    "\n",
    "### 5.1  Check differencing the data th guide choice of I parameter\n",
    "\n",
    "# Use AD Fuller test to test if time series is stationary\n",
    "# Null hypothesis of the ADF test is that the time series is non-stationary\n",
    "\n",
    "result = adfuller(train.total_claim_amount)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "# p < 0.5, so we can infer time series is stationary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I - Integrated\n",
    "# Plot total claim amount for 1st order differencing\n",
    "\n",
    "# Original Series\n",
    "plt.rcParams.update({'figure.figsize':(9,6), 'figure.dpi':120})\n",
    "fig, axes = plt.subplots(2, 2, sharex=False)\n",
    "axes[0, 0].plot(train.total_claim_amount.dropna()); axes[0, 0].set_title('Original Series')\n",
    "plot_acf(train.total_claim_amount.dropna(), ax=axes[0, 1], lags=30)\n",
    "\n",
    "# 1st Differencing\n",
    "axes[1, 0].plot(train.total_claim_amount.diff()); axes[1, 0].set_title('1st Order Differencing')\n",
    "plot_acf(train.total_claim_amount.diff().dropna(), ax=axes[1, 1], lags=30)\n",
    "plt.show()\n",
    "\n",
    "# 1st Order Differencing ACF Plot indicates over-differenced data (strong negative first lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  5.2 Auto-Regression\n",
    "\n",
    "# PACF plot of 1st differenced series\n",
    "plt.rcParams.update({'figure.figsize':(9,2.5), 'figure.dpi':120})\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, sharex=False)\n",
    "axes[0].plot(train.total_claim_amount); axes[0].set_title('Original Series')\n",
    "plot_pacf(train.total_claim_amount.dropna(), ax=axes[1], lags=20)\n",
    "plt.show()\n",
    "\n",
    "# Partial-autocorrelation, with sig. correlation at lag 1, so an AR terms is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  5.3 Moving Average\n",
    "plt.rcParams.update({'figure.figsize':(9,2.5), 'figure.dpi':120})\n",
    "fig, axes = plt.subplots(1, 2, sharex=False)\n",
    "axes[0].plot(train.total_claim_amount); axes[0].set_title('Original Data')\n",
    "plot_acf(train.total_claim_amount.dropna(), ax=axes[1])\n",
    "plt.show()\n",
    "\n",
    "# Autocorrelation at lag 1 and (somewhat) at lag 2, so we need an MA term (use 1 MA term to be conservative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Train ARIMA X Models\n",
    "# ARIMA (p,d,q) - (AR specification, Integration order, MA specification)\n",
    "\n",
    "# Predictors (endogenous and exogenous)\n",
    "endog = train['total_claim_amount']\n",
    "exog_features = ['age_max', 'DOW__1', 'DOW__2', 'DOW__3', 'DOW__4', 'DOW__5', 'DOW__6']\n",
    "exog = train[exog_features]\n",
    "\n",
    "# Define and fit model\n",
    "def1 = sm.tsa.statespace.SARIMAX(endog, exog, order=(1,0,1))\n",
    "mod1 = def1.fit(disp=False)\n",
    "print(mod1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit model after dropping the MA term \n",
    "def2 = sm.tsa.statespace.SARIMAX(endog, exog, order=(1,0,0))\n",
    "mod2 = def2.fit(disp=False)\n",
    "\n",
    "print(mod2.summary())\n",
    "res2 = mod2.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residual errors\n",
    "fig, ax = plt.subplots(1,2, figsize=(9,2)) \n",
    "res2.plot(title=\"Residuals\", ax=ax[0])\n",
    "res2.plot(kind='kde', title='Density', ax=ax[1])\n",
    "plt.show()\n",
    "\n",
    "# Actual vs Fitted\n",
    "# Add fitted values onto training set\n",
    "train = pd.concat([train, pd.DataFrame({'ARIMA_Fitted' : mod2.fittedvalues})], axis=1, ignore_index=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,2.5))\n",
    "plt.plot(train['incident_date'], train['total_claim_amount'] ,color='cadetblue', label='Actuals')\n",
    "plt.plot(train['incident_date'], train['ARIMA_Fitted'], color='orange', label='Fitted Value')\n",
    "legend = ax.legend(loc='upper left', shadow=False, fontsize='x-small')\n",
    "ax.set_title('Actuals vs Fitted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of Sample Test\n",
    "forecast = mod2.get_forecast(steps=len(test), exog=test[exog_features], alpha=0.05)\n",
    "forecast_ci = forecast.conf_int()\n",
    "forecast_ci.columns = [\"Lower Bound\",\"Upper Bound\"]\n",
    "\n",
    "# Add forecasts onto test set\n",
    "test = pd.concat([test, pd.DataFrame({'Forecast' : forecast.predicted_mean}), forecast_ci], axis=1, ignore_index=False)\n",
    "\n",
    "# Forecast Error\n",
    "arima_rmse = np.sqrt(np.mean((test.total_claim_amount - test.Forecast)**2))\n",
    "arima_mae = np.mean(np.abs(test.total_claim_amount - test.Forecast))\n",
    "\n",
    "print(\"RMSE: \" + str(round(arima_rmse)))\n",
    "print(\"MAE: \" + str(round(arima_mae)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart whole data set with test set forecast\n",
    "fig, ax = plt.subplots(figsize=(9,2.5))\n",
    "npre = 4\n",
    "ax.set(title='Total Claim Amount', xlabel='Date', ylabel='Million Dollars')\n",
    "# Plot data points\n",
    "plt.plot(df['incident_date'], df['total_claim_amount'], label='Observed',  markersize=1)\n",
    "train.plot(x='incident_date', y='ARIMA_Fitted', ax=ax, style='orange', label='Fitted Values', linewidth=1, linestyle='--')\n",
    "# Plot predictions\n",
    "test.plot(x='incident_date', y='Forecast', ax=ax, style='g', label='Out of Sample Forecast')\n",
    "#ax.fill_between(x=test['incident_date'], y1=test['Lower Bound'], y2=test['Upper Bound'], color='g', alpha=0.1, label=\"95% Confidence\")\n",
    "legend = ax.legend(loc='lower right', fontsize='xx-small')\n",
    "\n",
    "\n",
    "# Test set with forecast\n",
    "fig, ax = plt.subplots(figsize=(9,2.5))\n",
    "npre = 4\n",
    "ax.set(title='Total Claim Amount', xlabel='Date', ylabel='Million Dollars')\n",
    "# Plot data points\n",
    "plt.plot(test['incident_date'], test['total_claim_amount'], label='Observed', marker='o', markersize=3, linewidth=1)\n",
    "#test.plot(x='incident_date', y='total_claim_amount', ax=ax, label='Observed', marker='o', markersize=4)\n",
    "# Plot predictions\n",
    "test.plot(x='incident_date', y='Forecast', ax=ax, style='g', label='Out of Sample Forecast')\n",
    "# Plot Confidence Intervals\n",
    "ax.fill_between(x=test['incident_date'], y1=test['Lower Bound'], y2=test['Upper Bound'], color='g', alpha=0.05, label=\"95% Confidence\")\n",
    "legend = ax.legend(loc='lower right', fontsize='xx-small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6. Holt-Winters & ARIMAX Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Comparison\n",
    "\n",
    "# Test set with forecast\n",
    "fig, ax = plt.subplots(figsize=(9, 2.5))\n",
    "npre = 4\n",
    "ax.set(title='Total Claim Amount', xlabel='Date', ylabel='Million Dollars')\n",
    "# Plot data points\n",
    "plt.plot(test['incident_date'], test['total_claim_amount'], label='Observed', marker='o', markersize=3, linewidth=1)\n",
    "# Plot predictions\n",
    "test.plot(x='incident_date', y='HW_Forecast', ax=ax, style='orange', label='Holt-Winters Forecast')\n",
    "test.plot(x='incident_date', y='Forecast', ax=ax, style='g', label='ARIMAX Forecast')\n",
    "# Plot Confidence Intervals\n",
    "legend = ax.legend(loc='lower right', fontsize='xx-small')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast Error\n",
    "HW_mae = np.mean(np.abs(test.total_claim_amount - test.HW_Forecast))\n",
    "ARIMAX_mae = np.mean(np.abs(test.total_claim_amount - test.Forecast))\n",
    "\n",
    "print(\"MAE\")\n",
    "print(\"Holt-Winters: \" + str(f\"{round(HW_mae):,d}\"))\n",
    "print(\"ARIMAX:       \" + str(f\"{round(ARIMAX_mae):,d}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Auto-ARIMAX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################\n",
    "# 7. Auto-ARIMAX\n",
    "\n",
    "model_auto = pm.auto_arima(train['total_claim_amount'], train[exog_features], start_p=1, start_q=1,\n",
    "                      test='adf',       # use adftest to find optimal 'd'\n",
    "                      max_p=3, max_q=3, # maximum p and q\n",
    "                      m=1,              # frequency of series\n",
    "                      d=None,           # let model determine 'd'\n",
    "                      seasonal=False,   # No Seasonality\n",
    "                      start_P=0, \n",
    "                      D=0, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=True)\n",
    "\n",
    "print(model_auto.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add forecasts onto test set\n",
    "train_pct = 0.8  \n",
    "train = df.iloc[0:round(len(df)*train_pct)]\n",
    "test = df.iloc[round(len(df)*train_pct):]\n",
    "\n",
    "forecast_AX = model_auto.predict(n_periods=len(test), return_conf_int=False, exogenous = test[exog_features])\n",
    "\n",
    "test = pd.concat([test, pd.DataFrame({'Forecast_AutoARIMAX' : forecast_AX}, index = test.index)], axis=1, ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Auto-SARIMAX (Seasonal ARIMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Auto-SARIMAX\n",
    "\n",
    "model_autos2 = pm.auto_arima(train['total_claim_amount'], train[['trend', 'age_max']], start_p=1, start_q=1,\n",
    "                      test='adf',       # use adftest to find optimal 'd'\n",
    "                      max_p=3, max_q=3, # maximum p and q\n",
    "                      m=7,              # frequency of series\n",
    "                      d=None,           # let model determine 'd'\n",
    "                      seasonal=True,    # No Seasonality\n",
    "                      start_P=0, \n",
    "                      D=1, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=True)\n",
    "\n",
    "print(model_autos2.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add forecasts onto test set\n",
    "forecast_ASX = model_autos2.predict(n_periods=len(test), exogenous = test[['trend', 'age_max']])\n",
    "\n",
    "test=pd.concat([test, pd.DataFrame({'Forecast_AutoSARIMAX' : forecast_ASX}, index = test.index)], axis=1, ignore_index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Auto-ARIMA with Auto-ARIMAX\n",
    "\n",
    "# Test set with forecast\n",
    "fig, ax = plt.subplots(figsize=(9, 3))\n",
    "npre = 4\n",
    "ax.set(title='Total Claim Amount', xlabel='Date', ylabel='Million Dollars')\n",
    "# Plot data points\n",
    "plt.plot(test['incident_date'], test['total_claim_amount'], label='Observed', marker='o', markersize=3, linewidth=1)\n",
    "# Plot predictions\n",
    "test.plot(x='incident_date', y='Forecast_AutoARIMAX', ax=ax, style='orange', label='Auto-ARMIAX')\n",
    "test.plot(x='incident_date', y='Forecast_AutoSARIMAX', ax=ax, style='g', label='Auto-SARIMAX')\n",
    "# Plot Confidence Intervals\n",
    "legend = ax.legend(loc='lower right', fontsize='xx-small')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast Error\n",
    "auto_arimax_mae = np.mean(np.abs(test.total_claim_amount - test.Forecast_AutoARIMAX))\n",
    "auto_sarimax_mae = np.mean(np.abs(test.total_claim_amount - test.Forecast_AutoSARIMAX))\n",
    "\n",
    "print(\"MAE\")\n",
    "print(\"Auto ARIMAX:  \" + str(f\"{round(auto_arimax_mae):,d}\"))\n",
    "print(\"Auto SARIMAX: \" + str(f\"{round(auto_sarimax_mae):,d}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
